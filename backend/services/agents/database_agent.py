# Code Generated by Sidekick is for learning and experimentation purposes only.
from models.projects import Project, FileMetadata
from models.analysis import AnalysisArtifact, ArtifactType, ArtifactStatus
from openai import AsyncOpenAI
import os
import re
import json
from dotenv import load_dotenv
import ast
from typing import Any, Dict, List, Optional, Tuple

load_dotenv(override=True)
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))


async def analyze_database_schema(project: Project):
    """
    Analyze database models and relationships
    """
    print(f"üíæ [DatabaseAgent] Analyzing database schema for project {project.id}")
    
    # Get files that contain database models
    model_files = await FileMetadata.filter(
        project=project
    ).all()
    
    if not model_files:
        print("‚ö†Ô∏è  [DatabaseAgent] No database models found")
        return 0
    
    # Extract model definitions
    models = []
    extract_path = f"storage/extracted/{project.id}"
    
    for file in model_files:
        full_path = os.path.join(extract_path, file.file_path)
        
        if not os.path.exists(full_path):
            continue
        
        with open(full_path, "r", encoding="utf-8", errors="ignore") as f:
            content = f.read()
        
        # Extract models based on language
        if file.extension == ".py":
            file_models = extract_python_models_ast(content, file.file_name)
        elif file.extension in [".js", ".ts"]:
            file_models = extract_js_models(content, file.file_name)
        else:
            continue
        
        models.extend(file_models)
    
    print(f"‚úÖ [DatabaseAgent] Found {len(models)} database models")
    
    # Generate ERD and documentation
    if models:
        await generate_database_documentation(project, models, model_files)
    
    return len(models)


def _dotted_name(node: ast.AST) -> Optional[str]:
    if isinstance(node, ast.Name):
        return node.id
    if isinstance(node, ast.Attribute):
        base = _dotted_name(node.value)
        return f"{base}.{node.attr}" if base else node.attr
    return None

def extract_python_models_ast(code: str, filename: str) -> List[Dict[str, Any]]:
    tree = ast.parse(code, filename=filename)
    models: List[Dict[str, Any]] = []

    def is_model_base(base: ast.AST) -> bool:
        name = _dotted_name(base) or ""
        # Tune this list to YOUR stack; avoid treating Pydantic BaseModel as DB model
        return name.endswith("models.Model") or name.endswith("Model") or name.endswith("DeclarativeBase")

    def classify_field_call(call: ast.Call) -> Tuple[Optional[str], Optional[str]]:
        fn = _dotted_name(call.func) or ""
        # Django-like
        if fn.endswith("ForeignKey") or fn.endswith("OneToOneField") or fn.endswith("ManyToManyField"):
            return ("relationship", fn.split(".")[-1])
        if fn.endswith("Field"):
            return ("field", fn.split(".")[-1])
        # SQLAlchemy-like
        if fn.endswith("Column") or fn.endswith("mapped_column"):
            return ("field", fn.split(".")[-1])
        if fn.endswith("relationship"):
            return ("relationship", "relationship")
        return (None, None)

    for node in tree.body:
        if not isinstance(node, ast.ClassDef):
            continue

        if not any(is_model_base(b) for b in node.bases):
            continue

        fields = []
        relationships = []

        for stmt in node.body:
            # x = Something(...)
            if isinstance(stmt, ast.Assign) and len(stmt.targets) == 1 and isinstance(stmt.targets[0], ast.Name):
                attr_name = stmt.targets[0].id
                if isinstance(stmt.value, ast.Call):
                    kind, ftype = classify_field_call(stmt.value)
                    if kind == "field":
                        fields.append({"name": attr_name, "type": ftype})
                    elif kind == "relationship":
                        relationships.append({"field": attr_name, "type": ftype})

            # x: Type = Something(...)
            if isinstance(stmt, ast.AnnAssign) and isinstance(stmt.target, ast.Name):
                attr_name = stmt.target.id
                if isinstance(stmt.value, ast.Call):
                    kind, ftype = classify_field_call(stmt.value)
                    if kind == "field":
                        fields.append({"name": attr_name, "type": ftype})
                    elif kind == "relationship":
                        relationships.append({"field": attr_name, "type": ftype})

        models.append({
            "name": node.name,
            "file": filename,
            "fields": fields,
            "relationships": relationships,
        })

    return models


def extract_python_models(content: str, filename: str):
    """
    Extract database models from Python (Django, SQLAlchemy, Tortoise, etc.)
    """
    models = []
    
    # Pattern for class definitions - looking for common Model inheritance
    class_pattern = r'class\s+(\w+)\s*\((?:[^)]*(?:Model|BaseModel|models\.Model)[^)]*)\):'
    matches = re.finditer(class_pattern, content)
    
    for match in matches:
        model_name = match.group(1)
        class_start = match.start()
        
        # Find the class body (simplified - gets next 1000 chars)
        class_body = content[class_start:class_start + 1000]
        
        # Extract fields
        fields = []
        
        # Common ORM field patterns
        field_patterns = [
            r'(\w+)\s*=\s*(?:models\.)?(\w+Field)\(',  # Django/Tortoise
            r'(\w+)\s*=\s*Column\((\w+)',              # SQLAlchemy
            r'(\w+):\s*(\w+)\s*=\s*Field\(',           # Pydantic with Field
        ]
        
        for pattern in field_patterns:
            field_matches = re.findall(pattern, class_body)
            for field_name, field_type in field_matches:
                if field_name not in ['Meta', 'meta', '__tablename__']:
                    fields.append({
                        'name': field_name, 
                        'type': field_type
                    })
        
        # Extract relationships
        relationships = []
        rel_patterns = [
            r'(\w+)\s*=\s*(?:models\.)?ForeignKeyField\(["\'](?:models\.)?(\w+)["\']',
            r'(\w+)\s*=\s*relationship\(["\'](\w+)["\']',
        ]
        
        for pattern in rel_patterns:
            rel_matches = re.findall(pattern, class_body)
            for field_name, related_model in rel_matches:
                relationships.append({
                    'field': field_name,
                    'related_to': related_model,
                    'type': 'foreign_key'
                })
        
        models.append({
            'name': model_name,
            'file': filename,
            'fields': fields,
            'relationships': relationships
        })
        
    return models


def extract_js_models(content: str, filename: str):
    """
    Extract database models from JavaScript/TypeScript (Sequelize, TypeORM, Mongoose)
    """
    models = []
    
    # Sequelize pattern
    sequelize_pattern = r'(\w+)\s*=\s*sequelize\.define\(["\'](\w+)["\']'
    matches = re.finditer(sequelize_pattern, content)
    for match in matches:
        model_name = match.group(2)
        models.append({
            'name': model_name,
            'file': filename,
            'fields': [],
            'relationships': []
        })
    
    # Mongoose schema pattern
    mongoose_pattern = r'const\s+(\w+)Schema\s*=\s*new\s+Schema\('
    matches = re.finditer(mongoose_pattern, content)
    for match in matches:
        schema_name = match.group(1)
        models.append({
            'name': schema_name,
            'file': filename,
            'fields': [],
            'relationships': []
        })
    
    # TypeORM Entity pattern
    entity_pattern = r'@Entity\(["\'](\w+)["\']\)\s*(?:export\s+)?class\s+(\w+)'
    matches = re.finditer(entity_pattern, content)
    
    for match in matches:
        class_name = match.group(2)
        models.append({
            'name': class_name,
            'file': filename,
            'fields': [],
            'relationships': []
        })
    
    return models


async def generate_database_documentation(project: Project, models: list, model_files: list):
    """
    Generate database schema documentation and ERD using LLM
    """
    # Format models for prompt
    models_text = []
    for model in models:
        fields_text = ", ".join([f"{f['name']}: {f['type']}" for f in model['fields']])
        relations_text = ", ".join([f"{r['field']} -> {r['related_to']}" for r in model['relationships']])
        
        models_text.append(
            f"Model: {model['name']} (in {model['file']})\n"
            f"  Fields: {fields_text}\n"
            f"  Relations: {relations_text}"
        )
    
    models_description = "\n\n".join(models_text)
    
    prompt = f"""Analyze this database schema and generate comprehensive documentation.

Project: {project.name}
Framework: {project.detected_framework}

Database Models:
{models_description}

Generate a JSON response with:
{{
  "summary": "Overview of the database schema",
  "tables": [
    {{
      "name": "users",
      "description": "Stores user account information",
      "key_fields": ["id", "email", "hashed_password"],
      "relationships": ["One-to-many with projects"]
    }}
  ],
  "relationships_summary": "Description of how tables relate",
  "mermaid_erd": "erDiagram\\n  USER ||--o{{ PROJECT : creates\\n  USER {{\\n    int id\\n    string email\\n  }}"
}}

Generate valid Mermaid ERD syntax for the mermaid_erd field.
Only respond with valid JSON, no markdown formatting."""
    
    try:
        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        db_content = response.choices[0].message.content
        
        # Clean response string to extract JSON
        if "```json" in db_content:
            db_content = db_content.split("```json")[1].split("```")[0].strip()
        elif "```" in db_content:
            db_content = db_content.split("```")[1].split("```")[0].strip()
        
        db_data = json.loads(db_content)
        
        # Store in AnalysisArtifact
        await AnalysisArtifact.create(
            project=project,
            artifact_type=ArtifactType.DATABASE_SCHEMA,
            content=db_data,
            status=ArtifactStatus.COMPLETED
        )
        
        print(f"‚úÖ [DatabaseAgent] Generated database documentation")
        
    except Exception as e:
        print(f"‚ùå [DatabaseAgent] Error generating documentation: {e}")
        await AnalysisArtifact.create(
            project=project,
            artifact_type=ArtifactType.DATABASE_SCHEMA,
            content={"error": str(e), "models": [m['name'] for m in models]},
            status=ArtifactStatus.FAILED,
            error_message=str(e)
        )